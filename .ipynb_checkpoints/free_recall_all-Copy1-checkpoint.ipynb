{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4704edd5-7bfd-4798-b161-4779696ed25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2127804/3225324295.py:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  year98 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/1998Cognition.csv')\n",
      "/tmp/ipykernel_2127804/3225324295.py:9: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  year04 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2004Cognition.csv')\n",
      "/tmp/ipykernel_2127804/3225324295.py:12: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  year10 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2010Cognition.csv')\n",
      "/tmp/ipykernel_2127804/3225324295.py:15: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  year16 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2016Cognition.csv')\n",
      "/tmp/ipykernel_2127804/3225324295.py:16: DtypeWarning: Columns (283) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  year18 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2018Cognition.csv')\n",
      "/tmp/ipykernel_2127804/3225324295.py:17: DtypeWarning: Columns (273) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  year20 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2020Cognition.csv')\n",
      "/tmp/ipykernel_2127804/3225324295.py:18: DtypeWarning: Columns (3,290) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  year22 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2022Cognition.csv')\n",
      "/tmp/ipykernel_2127804/3225324295.py:19: DtypeWarning: Columns (4,5,90,91) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  demo= pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/demsHRS.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load raw data file\n",
    "year96 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/1996Cognition.csv')\n",
    "year98 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/1998Cognition.csv')\n",
    "year00 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2000Cognition.csv')\n",
    "year02 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2002Cognition.csv')\n",
    "year04 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2004Cognition.csv')\n",
    "year06 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2006Cognition.csv')\n",
    "year08 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2008Cognition.csv')\n",
    "year10 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2010Cognition.csv')\n",
    "year12 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2012Cognition.csv')\n",
    "year14 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2014Cognition.csv')\n",
    "year16 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2016Cognition.csv')\n",
    "year18 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2018Cognition.csv')\n",
    "year20 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2020Cognition.csv')\n",
    "year22 = pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/2022Cognition.csv')\n",
    "demo= pd.read_csv('/mnt/home/tranha1/research/cbcclab/git_repos/experiments/Tran25longitudinal.git/CognitionData/demsHRS.csv')\n",
    "\n",
    "#Create list for names of columns in each year\n",
    "\n",
    "#96\n",
    "year_96 = ('E1174M1','E1174M2','E1174M3','E1174M4','E1174M5','E1174M6','E1174M7','E1174M8','E1174M9','E1174M10','E1174M11')\n",
    "\n",
    "#98\n",
    "\n",
    "year_98 = ('F1491M1','F1491M2','F1491M3','F1491M4','F1491M5','F1491M6','F1491M7','F1491M8','F1491M9','F1491M10','F1491M11')\n",
    "\n",
    "#00\n",
    "year_00 = ('G1666M1','G1666M2','G1666M3','G1666M4','G1666M5','G1666M6','G1666M7','G1666M8','G1666M9','G1666M10','G1666M11')\n",
    "\n",
    "#02\n",
    "year_02 = ('HD182M1','HD182M2','HD182M3','HD182M4','HD182M5','HD182M6','HD182M7','HD182M8','HD182M9','HD182M10')\n",
    "\n",
    "#04\n",
    "year_04 = ('JD182M1','JD182M2','JD182M3','JD182M4','JD182M5','JD182M6','JD182M7','JD182M8','JD182M9','JD182M10','JD182M11','JD182M12')\n",
    "\n",
    "#06\n",
    "year_06 = ('KD182M1','KD182M2','KD182M3','KD182M4','KD182M5','KD182M6','KD182M7','KD182M8','KD182M9','KD182M10')\n",
    "\n",
    "#08\n",
    "year_08 = ('LD182M1','LD182M2','LD182M3','LD182M4','LD182M5','LD182M6','LD182M7','LD182M8','LD182M9','LD182M10')\n",
    "\n",
    "#10\n",
    "year_10 = ('MD182M1','MD182M2','MD182M3','MD182M4','MD182M5','MD182M6','MD182M7','MD182M8','MD182M9','MD182M10','MD182M11','MD182M12','MD182M13','MD182M14','MD182M15')\n",
    "\n",
    "#12\n",
    "year_12 = ('ND182M1','ND182M2','ND182M3','ND182M4','ND182M5','ND182M6','ND182M7','ND182M8','ND182M9','ND182M10','ND182M11','ND182M12','ND182M13')\n",
    "\n",
    "#14\n",
    "year_14 = ('OD182M1','OD182M2','OD182M3','OD182M4','OD182M5','OD182M6','OD182M7','OD182M8','OD182M9','OD182M10','OD182M11','OD182M12','OD182M13','OD182M14')\n",
    "\n",
    "#16\n",
    "year_16= ('PD182M1','PD182M2','PD182M3','PD182M4', 'PD182M5', 'PD182M6','PD182M7','PD182M8','PD182M9','PD182M10', 'PD182M11','PD182M12', 'PD182M13', 'PD182M14','PD182M15','PD182M16','PD182M17','PD182M18')\n",
    "\n",
    "#18\n",
    "year_18 = ('QD182M1','QD182M2','QD182M3','QD182M4','QD182M5','QD182M6','QD182M7','QD182M8','QD182M9','QD182M10','QD182M11','QD182M12', 'QD182M13','QD182M14','QD182M15','QD182M16','QD182M17','QD182M18','QD182M19','QD182M20','QD182M21','QD182M22','QD182M23')\n",
    "\n",
    "#20\n",
    "year_20 = ('RD182M1', 'RD182M2','RD182M3','RD182M4','RD182M5','RD182M6','RD182M7','RD182M8','RD182M9','RD182M10','RD182M11','RD182M12','RD182M13','RD182M14')\n",
    "\n",
    "#22\n",
    "year_22 = ('SD182M1','SD182M2','SD182M3','SD182M4','SD182M5','SD182M6','SD182M7','SD182M8','SD182M9','SD182M10','SD182M11','SD182M12')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d6883-ee83-4e2a-889f-babf49e57779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8741d95c-137b-41e7-947a-c1be32800414",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map = {\n",
    "    1: \"BOOK\", 2: \"CHILD\", 3: \"GOLD\", 4: \"HOTEL\", 5: \"KING\", 6: \"MARKET\", 7: \"PAPER\", 8: \"RIVER\", 9: \"SKIN\", 10: \"TREE\",\n",
    "    11: \"BUTTER\", 12: \"COLLEGE\", 13: \"DOLLAR\", 14: \"EARTH\", 15: \"FLAG\", 16: \"HOME\", 17: \"MACHINE\", 18: \"OCEAN\", 19: \"SKY\", 20: \"WIFE\",\n",
    "    21: \"BLOOD\", 22: \"CORNER\", 23: \"ENGINE\", 24: \"GIRL\", 25: \"HOUSE\", 26: \"LETTER\", 27: \"ROCK\", 28: \"SHOES\", 29: \"VALLEY\", 30: \"WOMAN\",\n",
    "    31: \"BABY\", 32: \"CHURCH\", 33: \"DOCTOR\", 34: \"FIRE\", 35: \"GARDEN\", 36: \"PALACE\", 37: \"SEA\", 38: \"TABLE\", 39: \"VILLAGE\", 40: \"WATER\"\n",
    "}\n",
    "\n",
    "list1_96_14 = [  \n",
    "     \"HOTEL\", \"RIVER\", \"TREE\", \"SKIN\", \"GOLD\",\n",
    "     \"MARKET\", \"PAPER\", \"CHILD\", \"KING\", \"BOOK\"\n",
    " ]\n",
    "\n",
    "list11_96_14 = [\n",
    "    \"SKY\", \"OCEAN\", \"FLAG\", \"DOLLAR\", \"WIFE\",\n",
    "     \"MACHINE\", \"HOME\", \"EARTH\", \"COLLEGE\", \"BUTTER\"\n",
    " ]\n",
    "\n",
    "list21_96_14 = [\n",
    "     \"WOMAN\", \"ROCK\", \"BLOOD\", \"CORNER\", \"SHOES\",\n",
    "     \"LETTER\", \"GIRL\", \"HOUSE\", \"VALLEY\", \"ENGINE\"\n",
    " ]\n",
    "\n",
    "list31_96_14 = [\n",
    "     \"WATER\", \"CHURCH\", \"DOCTOR\", \"PALACE\", \"FIRE\",\n",
    "     \"GARDEN\", \"SEA\", \"VILLAGE\", \"BABY\", \"TABLE\"\n",
    " ]\n",
    "\n",
    "\n",
    "# Define the word lists\n",
    "list1_16_22 = [\"BOOK\", \"CHILD\", \"GOLD\", \"HOTEL\", \"KING\", \"MARKET\", \"PAPER\", \"RIVER\", \"SKIN\", \"TREE\"]\n",
    "list11_16_22 = [\"BUTTER\", \"COLLEGE\", \"DOLLAR\", \"EARTH\", \"FLAG\", \"HOME\", \"MACHINE\", \"OCEAN\", \"SKY\", \"WIFE\"]\n",
    "list21_16_22 = [\"BLOOD\", \"CORNER\", \"ENGINE\", \"GIRL\", \"HOUSE\", \"LETTER\", \"ROCK\", \"SHOES\", \"VALLEY\", \"WOMAN\"]\n",
    "list31_16_22 = [\"BABY\", \"CHURCH\", \"DOCTOR\", \"FIRE\", \"GARDEN\", \"PALACE\", \"SEA\", \"TABLE\", \"VILLAGE\", \"WATER\"]\n",
    "\n",
    "#already have id \n",
    "\n",
    "### process and group the person in their age group along with the probability\n",
    "\n",
    "#have 10 age group 20-29,30-39,40-49,50-59,60-69,70-79,80-89,90-99,100-110.\n",
    "#each group will have subgroups where consists of the visits year of the subgroup\n",
    "\n",
    "#find the id in each row by combining the 2 column together. in each column, find the visit years that they went to\n",
    "#find that person's id in each of the visit and calculate the probability in that visit\n",
    "#go to that visit(which will be a file), after that, caluclate the probability of that person's trial of that year \n",
    "#add that probability to the coressponding subgroup based on visit. \n",
    "#, calculate that visit year's probability and then add that probability to the subgroup in the age group\n",
    "\n",
    "#age group will be determined based on that person's first visit\n",
    "\n",
    "#### heads up, wording map changing in 2016,\n",
    "#if visit year > 13, use new word map ( need to change)\n",
    "#if visit year < 13, use old version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77ae83-54c1-45a8-b591-d7c94a6873fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AGE DISTRIBUTION DIAGNOSTIC ===\n",
      "Total participants: 45234\n",
      "Participants with valid first age: 42959\n",
      "Age range: 18.0 to 105.0\n",
      "Age statistics:\n",
      "count    42959.000000\n",
      "mean        60.427733\n",
      "std         10.944278\n",
      "min         18.000000\n",
      "25%         53.000000\n",
      "50%         57.000000\n",
      "75%         68.000000\n",
      "max        105.000000\n",
      "dtype: float64\n",
      "\n",
      "Participants by age group:\n",
      "  100-110: 14\n",
      "  20-29: 47\n",
      "  30-39: 405\n",
      "  40-49: 2949\n",
      "  50-59: 21728\n",
      "  60-69: 8232\n",
      "  70-79: 6584\n",
      "  80-89: 2606\n",
      "  90-99: 392\n",
      "\n",
      "=== STARTING MAIN PROCESSING ===\n",
      "Processed 1000 participants...\n",
      "Processed 2000 participants...\n",
      "Processed 3000 participants...\n",
      "Processed 4000 participants...\n",
      "Processed 5000 participants...\n",
      "Processed 6000 participants...\n",
      "Processed 7000 participants...\n",
      "Processed 8000 participants...\n",
      "Processed 9000 participants...\n",
      "Processed 10000 participants...\n",
      "Processed 11000 participants...\n",
      "Processed 12000 participants...\n",
      "Processed 13000 participants...\n",
      "Processed 14000 participants...\n",
      "Processed 15000 participants...\n",
      "Processed 16000 participants...\n",
      "Processed 17000 participants...\n",
      "Processed 18000 participants...\n",
      "Processed 19000 participants...\n",
      "Processed 20000 participants...\n",
      "Processed 20000 participants...\n",
      "Processed 21000 participants...\n",
      "Processed 21000 participants...\n",
      "Processed 22000 participants...\n",
      "Processed 23000 participants...\n",
      "Processed 24000 participants...\n",
      "Processed 25000 participants...\n",
      "Processed 26000 participants...\n",
      "Processed 27000 participants...\n",
      "Processed 28000 participants...\n",
      "Processed 29000 participants...\n",
      "Processed 30000 participants...\n",
      "Processed 31000 participants...\n",
      "Processed 32000 participants...\n",
      "Processed 33000 participants...\n",
      "Processed 34000 participants...\n",
      "Processed 35000 participants...\n",
      "Processed 36000 participants...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DEMO_HHID_COL = \"hhid\"        # Demo file HHID column\n",
    "DEMO_PN_COL = \"pn\"            # Demo file PN column\n",
    "VISIT_HHID_COL = \"HHID\"       # Visit file HHID column\n",
    "VISIT_PN_COL = \"PN\"           # Visit file PN column\n",
    "NEW_MAP_YEAR = 2016\n",
    "\n",
    "\n",
    "AGE_COLS = [\"age96\",\"age98\",\"age00\",\"age02\",\"age04\",\"age06\",\"age08\",\n",
    "            \"age10\",\"age12\",\"age14\",\"age16\",\"age18\",\"age20\",\"age22\"]\n",
    "\n",
    "# Convert age columns to numeric, handling spaces and invalid values\n",
    "for col in AGE_COLS:\n",
    "    if col in demo.columns:\n",
    "        # Strip whitespace and convert to numeric\n",
    "        demo[col] = pd.to_numeric(demo[col].astype(str).str.strip(), errors='coerce')\n",
    "\n",
    "# Also clean HHID and PN columns in demo file\n",
    "demo[DEMO_HHID_COL] = pd.to_numeric(demo[DEMO_HHID_COL], errors='coerce')\n",
    "demo[DEMO_PN_COL] = pd.to_numeric(demo[DEMO_PN_COL], errors='coerce')\n",
    "\n",
    "\n",
    "visit_files = {\n",
    "    1996: year96, 1998: year98, 2000: year00, 2002: year02,\n",
    "    2004: year04, 2006: year06, 2008: year08, 2010: year10,\n",
    "    2012: year12, 2014: year14, 2016: year16, 2018: year18,\n",
    "    2020: year20, 2022: year22,\n",
    "}\n",
    "\n",
    "# Clean HHID and PN columns in all visit files, turn them into the same type of data\n",
    "for year, df in visit_files.items():\n",
    "    df[VISIT_HHID_COL] = pd.to_numeric(df[VISIT_HHID_COL], errors='coerce')\n",
    "    df[VISIT_PN_COL] = pd.to_numeric(df[VISIT_PN_COL], errors='coerce')\n",
    "    # Create a composite key for faster lookup\n",
    "    df['_lookup_key'] = df[VISIT_HHID_COL].astype(str) + '_' + df[VISIT_PN_COL].astype(str) \n",
    "\n",
    "#create years\n",
    "TRIAL_COLS_MAP = {\n",
    "    1996: year_96,  1998: year_98,  2000: year_00,  2002: year_02,\n",
    "    2004: year_04,  2006: year_06,  2008: year_08,  2010: year_10,\n",
    "    2012: year_12,  2014: year_14,  2016: year_16,  2018: year_18,\n",
    "    2020: year_20,  2022: year_22,\n",
    "}\n",
    "\n",
    "OLD_LISTS = {\"list1\": list1_96_14,  \"list11\": list11_96_14,\n",
    "             \"list21\": list21_96_14, \"list31\": list31_96_14}\n",
    "NEW_LISTS = {\"list1\": list1_16_22,  \"list11\": list11_16_22,\n",
    "             \"list21\": list21_16_22, \"list31\": list31_16_22}\n",
    "\n",
    "#use old word map for years before 2016 and new word map for after 2016\n",
    "def lists_for_year(yr):\n",
    "    return NEW_LISTS if yr >= NEW_MAP_YEAR else OLD_LISTS\n",
    "\n",
    "#go through each row, find word through dictionary and index, divide 10 values to get probability \n",
    "def prob_from_row(row: pd.Series, trial_cols, lists):\n",
    "   \n",
    "    trials = row[list(trial_cols)]\n",
    "\n",
    "    processed = []\n",
    "    for num in trials:\n",
    "        num_str = str(num).strip()\n",
    "        if not num_str or num_str == 'nan':\n",
    "            processed.append(0)\n",
    "            continue\n",
    "        try:\n",
    "            number = int(num_str)\n",
    "        except ValueError:\n",
    "            processed.append(0)\n",
    "            continue\n",
    "        if number not in word_map:\n",
    "            processed.append(0)\n",
    "            continue\n",
    "        word = word_map[number]\n",
    "        if number in range(1, 11):\n",
    "            processed.append(lists[\"list1\"].index(word) + 1 if word in lists[\"list1\"] else -1)\n",
    "        elif number in range(11, 21):\n",
    "            processed.append(lists[\"list11\"].index(word) + 1 if word in lists[\"list11\"] else -1)\n",
    "        elif number in range(21, 31):\n",
    "            processed.append(lists[\"list21\"].index(word) + 1 if word in lists[\"list21\"] else -1)\n",
    "        elif number in range(31, 41):\n",
    "            processed.append(lists[\"list31\"].index(word) + 1 if word in lists[\"list31\"] else -1)\n",
    "\n",
    "    first_10 = processed[:10]\n",
    "    unique_valid = {v for v in first_10 if v > 0}\n",
    "    return len(unique_valid) / 10\n",
    "\n",
    "#Create age groups, put the participants in the different age groups\n",
    "AGE_BINS = [(20,29),(30,39),(40,49),(50,59),\n",
    "            (60,69),(70,79),(80,89),(90,99),(100,110)]\n",
    "\n",
    "def age_group(age):\n",
    "    for lo,hi in AGE_BINS:\n",
    "        if lo <= age <= hi: \n",
    "            return f\"{lo}-{hi}\"\n",
    "    return None\n",
    "    \n",
    "# find single row in a visit that matches HHID and PN\n",
    "def find_participant_in_visit(hhid, pn, visit_df):\n",
    "    \"\"\"\n",
    "    Find participant in visit file using HHID and PN.\n",
    "    Returns the row if found, None otherwise.\n",
    "    \"\"\"\n",
    "    lookup_key = f\"{hhid}_{pn}\"\n",
    "    matches = visit_df[visit_df['_lookup_key'] == lookup_key]\n",
    "    return matches.iloc[0] if not matches.empty else None\n",
    "\n",
    "#Find first time participant appears and sort them into age groups, check and sort ages\n",
    "def check_age_distribution():\n",
    "    demo_first_ages = (\n",
    "        demo[AGE_COLS]\n",
    "        .apply(lambda row: row.dropna().iloc[0] if not row.dropna().empty else None, axis=1)\n",
    "    )\n",
    "    \n",
    "    print(\"=== AGE DISTRIBUTION DIAGNOSTIC ===\")\n",
    "    print(f\"Total participants: {len(demo)}\")\n",
    "    print(f\"Participants with valid first age: {demo_first_ages.notna().sum()}\")\n",
    "    print(f\"Age range: {demo_first_ages.min():.1f} to {demo_first_ages.max():.1f}\")\n",
    "    print(f\"Age statistics:\")\n",
    "    print(demo_first_ages.describe())\n",
    "    \n",
    "    # Count by age groups\n",
    "    age_counts = {}\n",
    "    for age in demo_first_ages.dropna():\n",
    "        grp = age_group(age)\n",
    "        if grp:\n",
    "            age_counts[grp] = age_counts.get(grp, 0) + 1\n",
    "    \n",
    "    print(f\"\\nParticipants by age group:\")\n",
    "    for grp in sorted(age_counts.keys()):\n",
    "        print(f\"  {grp}: {age_counts[grp]}\")\n",
    "    \n",
    "    return demo_first_ages\n",
    "\n",
    "\n",
    "\n",
    "# Initialize age_prob dictionary\n",
    "#Filter participants (valid ID and in age bins)\n",
    "#Group them by first visit age into age bins\n",
    "#process probability and append to age groups\n",
    "age_prob = {f\"{lo}-{hi}\": {yr: [] for yr in visit_files} for lo,hi in AGE_BINS}\n",
    "\n",
    "YEAR_FROM_COL = dict(zip(range(1996,2024,2), AGE_COLS))\n",
    "\n",
    "# Run diagnostic first\n",
    "first_ages = check_age_distribution()\n",
    "\n",
    "# Main processing loop\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "no_visits_count = 0\n",
    "\n",
    "print(\"\\n=== STARTING MAIN PROCESSING ===\")\n",
    "\n",
    "for _, person in demo.iterrows():\n",
    "    # Get participant IDs\n",
    "    hhid = person[DEMO_HHID_COL]\n",
    "    pn = person[DEMO_PN_COL]\n",
    "    \n",
    "    # Skip if invalid IDs\n",
    "    if pd.isna(hhid) or pd.isna(pn):\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Get all visits with valid ages for this participant\n",
    "    visits = []\n",
    "    for yr, col in YEAR_FROM_COL.items():\n",
    "        age_val = person[col]\n",
    "        if pd.notna(age_val) and age_val > 0:\n",
    "            visits.append((yr, age_val))\n",
    "    \n",
    "    if not visits:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Use first visit age to determine age group\n",
    "    first_year, first_age = visits[0]\n",
    "    grp = age_group(first_age)\n",
    "    \n",
    "    if grp is None:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Process all visits for this person\n",
    "    visits_found = 0\n",
    "    for yr, _ in visits:\n",
    "        visit_df = visit_files[yr]\n",
    "        \n",
    "        # Find participant in visit file\n",
    "        participant_row = find_participant_in_visit(hhid, pn, visit_df)\n",
    "        \n",
    "        if participant_row is None:\n",
    "            continue\n",
    "        \n",
    "        # Calculate probability for this visit\n",
    "        try:\n",
    "            prob = prob_from_row(\n",
    "                participant_row,\n",
    "                trial_cols=TRIAL_COLS_MAP[yr],\n",
    "                lists=lists_for_year(yr)\n",
    "            )\n",
    "            age_prob[grp][yr].append(prob)\n",
    "            visits_found += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing participant {hhid}-{pn} for year {yr}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if visits_found > 0:\n",
    "        processed_count += 1\n",
    "    else:\n",
    "        no_visits_count += 1\n",
    "    \n",
    "    if processed_count % 1000 == 0:\n",
    "        print(f\"Processed {processed_count} participants...\")\n",
    "\n",
    "\n",
    "print(f\"\\n=== FINAL RESULTS ===\")\n",
    "print(f\"Total processed: {processed_count}\")\n",
    "print(f\"Total skipped (invalid age/ID): {skipped_count}\")\n",
    "print(f\"Total with no matching visits: {no_visits_count}\")\n",
    "\n",
    "# Show final age_prob summary\n",
    "print(f\"\\n=== AGE GROUP SUMMARY ===\")\n",
    "for grp in sorted(age_prob.keys()):\n",
    "    total_obs = sum(len(age_prob[grp][yr]) for yr in age_prob[grp])\n",
    "    if total_obs > 0:\n",
    "        print(f\"{grp}: {total_obs} observations\")\n",
    "        # Show year-by-year breakdown\n",
    "        year_counts = {yr: len(age_prob[grp][yr]) for yr in age_prob[grp] if len(age_prob[grp][yr]) > 0}\n",
    "        if year_counts:\n",
    "            print(f\"  Years: {dict(sorted(year_counts.items()))}\")\n",
    "    else:\n",
    "        print(f\"{grp}: EMPTY\")\n",
    "\n",
    "# Show some sample probabilities\n",
    "print(f\"\\n=== SAMPLE PROBABILITIES ===\")\n",
    "for grp in sorted(age_prob.keys()):\n",
    "    for yr in sorted(age_prob[grp].keys()):\n",
    "        if len(age_prob[grp][yr]) > 0:\n",
    "            sample_probs = age_prob[grp][yr][:5]  # First 5 probabilities\n",
    "            print(f\"{grp} {yr}: {sample_probs}\")\n",
    "            break  # Only show first year with data for each group\n",
    "\n",
    "print(f\"\\n=== PROCESSING COMPLETE ===\")\n",
    "print(\"The age_prob dictionary is now populated with probabilities grouped by age and year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cf9a1-0d13-4a6b-b02a-0668613e3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_average_probabilities(age_prob_dict):\n",
    "    \"\"\"\n",
    "    Calculate average probability for each age group and year.\n",
    "    \n",
    "    Args:\n",
    "        age_prob_dict: Dictionary with structure {age_group: {year: [probabilities]}}\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with structure {age_group: {year: average_probability}}\n",
    "    \"\"\"\n",
    "    age_prob_averages = {}\n",
    "    \n",
    "    for age_group in age_prob_dict.keys():\n",
    "        age_prob_averages[age_group] = {}\n",
    "        \n",
    "        for year in age_prob_dict[age_group].keys():\n",
    "            probabilities = age_prob_dict[age_group][year]\n",
    "            \n",
    "            if len(probabilities) > 0:\n",
    "                age_prob_averages[age_group][year] = np.mean(probabilities)\n",
    "            else:\n",
    "                age_prob_averages[age_group][year] = None\n",
    "    \n",
    "    return age_prob_averages\n",
    "\n",
    "# Usage:\n",
    "age_prob_averages = calculate_average_probabilities(age_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4c59f-29cc-4ccd-b1c0-0b9c0697e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_prob_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ac9a9-b4ee-40af-a76f-e4b83287f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_age_probabilities(age_prob_averages):\n",
    "    \"\"\"\n",
    "    Plot average probabilities for all age groups over time.\n",
    "    \n",
    "    Args:\n",
    "        age_prob_averages: Dictionary with structure {age_group: {year: average_probability}}\n",
    "    \"\"\"\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Define years (1996 to 2022 with 2-year gaps)\n",
    "    years = list(range(1996, 2024, 2))\n",
    "    \n",
    "    # Get all age groups sorted by actual age (not alphabetically)\n",
    "    def sort_age_groups(age_group):\n",
    "        # Extract the first number from age group like \"20-29\" -> 20\n",
    "        return int(age_group.split('-')[0])\n",
    "    \n",
    "    age_groups = sorted(age_prob_averages.keys(), key=sort_age_groups)\n",
    "    \n",
    "    # Define colors for each age group\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(age_groups)))\n",
    "    \n",
    "    # Plot each age group\n",
    "    for i, age_group in enumerate(age_groups):\n",
    "        # Get probabilities for this age group\n",
    "        probs = []\n",
    "        for year in years:\n",
    "            prob = age_prob_averages[age_group].get(year)\n",
    "            probs.append(prob)\n",
    "        \n",
    "        # Plot the line (skip None values)\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        for year, prob in zip(years, probs):\n",
    "            if prob is not None:\n",
    "                x_vals.append(year)\n",
    "                y_vals.append(prob)\n",
    "        \n",
    "        if x_vals:  # Only plot if there's data\n",
    "            plt.plot(x_vals, y_vals, marker='o', linewidth=2, \n",
    "                    label=age_group, color=colors[i])\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Average Probability', fontsize=12)\n",
    "    plt.title('Average Probability by Age Group Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(years, rotation=45)\n",
    "    \n",
    "    # Set x-axis limits to show all years\n",
    "    plt.xlim(1994, 2024)\n",
    "    \n",
    "    # Adjust layout to prevent legend cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_age_probabilities(age_prob_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03371f37-3b26-4686-9f6c-d27dd92617e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
